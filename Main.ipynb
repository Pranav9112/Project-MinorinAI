{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comprehensive Answer Evaluation Tool - NLP Based\n",
    "\n",
    "The code aims to evaluate a question dataset, given that answers are provided, and a reference text is available. The evaluation is based on three parts: a keyword generator/counter, accounting for 20% of the overall marks, 20% for grammar, and the rest on semantic"
   ],
   "id": "10cf4c8cdd03ce6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports for NLP",
   "id": "fa3c27c95a212aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:25.368389Z",
     "start_time": "2026-01-17T15:49:25.332992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from PyPDF2 import PdfReader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "id": "89db02be25935d5",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Basic NLP Tasks\n",
    "1. Tokenization\n",
    "2. Stopword removal\n",
    "3. N-grams (unigrams, bigrams trigrams)"
   ],
   "id": "79c8d00609e7bb54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:25.680923Z",
     "start_time": "2026-01-17T15:49:25.378928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "STOPWORDS = {\n",
    "    \"the\",\"is\",\"in\",\"and\",\"to\",\"of\",\"a\",\"an\",\"for\",\"on\",\"with\",\"as\",\n",
    "    \"by\",\"this\",\"that\",\"it\",\"from\",\"are\",\"was\",\"were\",\"be\",\"has\",\"had\",\n",
    "    \"have\",\"at\",\"or\",\"but\",\"not\",\"which\",\"their\",\"its\",\"also\"\n",
    "}\n",
    "\n",
    "\n",
    "# PDF Processing\n",
    "pdf_path = 'text.pdf'\n",
    "reader = PdfReader(pdf_path)\n",
    "\n",
    "student_text = \"\"\n",
    "for page in reader.pages:\n",
    "    student_text += page.extract_text() + \" \"\n",
    "\n",
    "student_text = student_text.lower()\n",
    "\n",
    "# JSON Processing\n",
    "json_path = 'history_eval_dataset_v2.json'\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    qa = json.load(f)\n",
    "\n",
    "reference_text = \" \".join(\n",
    "    item[\"reference\"] for item in qa if \"reference\" in item\n",
    ").lower()\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = RegexpTokenizer(r'\\b[a-zA-Z]+\\b')\n",
    "stop_words = STOPWORDS\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [w for w in tokens if w not in stop_words]\n",
    "\n",
    "student_tokens = preprocess(student_text)\n",
    "reference_tokens = preprocess(reference_text)\n",
    "\n",
    "# N-grams\n",
    "def get_ngrams(tokens, n):\n",
    "    return Counter(ngrams(tokens, n))\n",
    "\n",
    "student_uni = Counter(student_tokens)\n",
    "student_bi = get_ngrams(student_tokens, 2)\n",
    "student_tri = get_ngrams(student_tokens, 3)\n",
    "\n",
    "ref_uni = Counter(reference_tokens)\n",
    "ref_bi = get_ngrams(reference_tokens, 2)\n",
    "ref_tri = get_ngrams(reference_tokens, 3)\n",
    "\n",
    "# Keywords Generation\n",
    "def common_terms(c1, c2):\n",
    "    common = {}\n",
    "    for k in c1:\n",
    "        if k in c2:\n",
    "            common[k] = min(c1[k], c2[k])\n",
    "    return Counter(common)\n",
    "\n",
    "common_uni = common_terms(student_uni, ref_uni)\n",
    "common_bi = common_terms(student_bi, ref_bi)\n",
    "common_tri = common_terms(student_tri, ref_tri)\n",
    "\n",
    "uni = []\n",
    "bi = []\n",
    "tri = []\n",
    "u_uni = set()\n",
    "u_bi = set()\n",
    "u_tri = set()\n",
    "\n",
    "for w, c in common_uni.most_common():\n",
    "    uni.append(w)\n",
    "for w, c in common_bi.most_common():\n",
    "    bi.append(w)\n",
    "for w, c in common_tri.most_common():\n",
    "    tri.append(w)\n",
    "\n",
    "for tri_g in tri:\n",
    "    tri_set = set(tri_g)\n",
    "\n",
    "    # Unigrams in trigrams\n",
    "    for u in uni:\n",
    "        if u in tri_set:\n",
    "            u_uni.add(u)\n",
    "\n",
    "    # bigrams in trigram\n",
    "    tri_bigrams = {(tri_g[0], tri_g[1]), (tri_g[1], tri_g[2])}\n",
    "\n",
    "    for b in bi:\n",
    "        if b in tri_bigrams:\n",
    "            u_bi.add(b)\n",
    "\n",
    "    # trigrams that have unigrams and bigrams\n",
    "    if any(\n",
    "        b in tri_bigrams for b in bi\n",
    "    ):\n",
    "        u_tri.add(tri_g)\n",
    "\n",
    "u_uni = list(u_uni)\n",
    "u_bi = list(u_bi)\n",
    "u_tri = list(u_tri)\n"
   ],
   "id": "5008fbbb4c9348c0",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Vectorization\n",
    " Make vectors, which are count values of each unigram, bigram, trigram from the keyword list, as a segment of evaluation."
   ],
   "id": "8a0d9797851a1068"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:25.712027Z",
     "start_time": "2026-01-17T15:49:25.693443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vector(tokens, uni_keys, bi_keys, tri_keys):\n",
    "    vec = []\n",
    "\n",
    "    token_counts = Counter(tokens)\n",
    "    bigram_counts = Counter(ngrams(tokens, 2))\n",
    "    trigram_counts = Counter(ngrams(tokens, 3))\n",
    "\n",
    "    for u in uni_keys:\n",
    "        vec.append(token_counts.get(u, 0)*0.2)\n",
    "\n",
    "    for b in bi_keys:\n",
    "        vec.append(bigram_counts.get(b, 0)*0.3)\n",
    "\n",
    "    for t in tri_keys:\n",
    "        vec.append(trigram_counts.get(t, 0)*0.5)\n",
    "\n",
    "    return vec"
   ],
   "id": "419061caa315cbf",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization & feature vectorization",
   "id": "3dc3d3ba9ad2d9dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:25.743204Z",
     "start_time": "2026-01-17T15:49:25.725131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_stu = []\n",
    "X_ref = []\n",
    "y_stu = []\n",
    "for item in qa:\n",
    "    tokens_stu = preprocess(item[\"student_answer\"])\n",
    "    X_stu.append(vector(tokens_stu, uni, bi, tri))\n",
    "    tokens_ref = preprocess(item[\"reference\"])\n",
    "    X_ref.append(vector(tokens_ref, uni, bi, tri))\n",
    "    y_stu.append(item[\"score\"])\n"
   ],
   "id": "47ad722a364eacdc",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Mark calculation based on keyword presence",
   "id": "67791cb33a6146f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:25.773581Z",
     "start_time": "2026-01-17T15:49:25.758588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_key_stu = []\n",
    "x_val_stu = []\n",
    "x_key_ref = []\n",
    "x_val_keyword = []\n",
    "\n",
    "def feature_sum(feature_vec_stu, feature_vec_ref, x_key_stu, x_key_ref, x_val):\n",
    "\n",
    "\n",
    "    for student_features in feature_vec_stu:\n",
    "        total = sum(student_features)\n",
    "        x_key_stu.append(total)\n",
    "\n",
    "    for teach_features in feature_vec_ref:\n",
    "        total = sum(teach_features)\n",
    "        x_key_ref.append(total)\n",
    "\n",
    "    if len(x_key_stu) == len(x_key_ref):\n",
    "        for i in range(len(x_key_stu)):\n",
    "            j = (x_key_stu[i]/x_key_ref[i])*2\n",
    "            x_val.append(j)\n",
    "\n",
    "feature_sum(X_stu, X_ref, x_key_stu, x_key_ref, x_val_keyword)\n",
    "\n",
    "print(x_val_keyword)\n"
   ],
   "id": "5fa0994ee61359b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.0, 0.0, 1.5294117647058825, 0.0, 0.0, 0.0, 1.5555555555555556, 0.0, 1.6, 0.0, 0.8979591836734697, 0.08163265306122452, 0.5000000000000001, 0.25000000000000006, 0.8888888888888888, 0.4444444444444444, 1.2000000000000002, 0.0]\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Word2Vec and MLPRegressor for evaluating semantics",
   "id": "d15618c628df3e62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:26.101930Z",
     "start_time": "2026-01-17T15:49:25.865995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentences = []\n",
    "for i in student_tokens:\n",
    "    sentences.append(i)\n",
    "\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "def sentence_vector(tokens, model):\n",
    "    vectors = []\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "def semantic_similarity(ref_text, stu_text, model):\n",
    "    ref_tokens = preprocess(ref_text)\n",
    "    stu_tokens = preprocess(stu_text)\n",
    "\n",
    "    v_ref = sentence_vector(ref_tokens, model).reshape(1, -1)\n",
    "    v_stu = sentence_vector(stu_tokens, model).reshape(1, -1)\n",
    "\n",
    "    return cosine_similarity(v_ref, v_stu)[0][0]\n",
    "\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for item in qa:\n",
    "    sim = semantic_similarity(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"],\n",
    "        w2v\n",
    "    )\n",
    "\n",
    "    features = [\n",
    "        sim,\n",
    "        len(preprocess(item[\"student_answer\"]))\n",
    "    ]\n",
    "\n",
    "    X.append(features)\n",
    "    y.append(item[\"score\"])\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(16, 8),\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "for p, a in zip(pred[:5], y_test[:5]):\n",
    "    print(f\"Predicted: {p:.2f} | Actual: {a}\")\n"
   ],
   "id": "1ae9ff32548e8df5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7684730158121744\n",
      "Predicted: 4.78 | Actual: 4\n",
      "Predicted: 4.09 | Actual: 4\n",
      "Predicted: 4.09 | Actual: 4\n",
      "Predicted: 2.27 | Actual: 2\n"
     ]
    }
   ],
   "execution_count": 181
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting using a different dataset than the trained one.",
   "id": "86816d6f0a6b5374"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:26.211196Z",
     "start_time": "2026-01-17T15:49:26.125134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"hist_100.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for item in data:\n",
    "    sentences.append(preprocess(item[\"reference\"]))\n",
    "\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for item in data:\n",
    "    sim = semantic_similarity(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"],\n",
    "        w2v\n",
    "    )\n",
    "\n",
    "    features = [\n",
    "        sim,\n",
    "        len(preprocess(item[\"student_answer\"]))\n",
    "    ]\n",
    "\n",
    "    X.append(features)\n",
    "    y.append(item[\"score\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(model.score(X_test, y))\n",
    "\n",
    "for p, a in zip(pred[:5], y[:5]):\n",
    "    print(f\"Predicted: {p:.2f} | Actual: {a}\")\n"
   ],
   "id": "6195b61b1d523a89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6377301617344744\n",
      "Predicted: 5.33 | Actual: 4\n",
      "Predicted: 3.78 | Actual: 3\n",
      "Predicted: 2.85 | Actual: 2\n",
      "Predicted: 0.08 | Actual: 0\n",
      "Predicted: 3.83 | Actual: 5\n"
     ]
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using Word2Vec and ridge regression",
   "id": "7b9595e75b92c259"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:26.288077Z",
     "start_time": "2026-01-17T15:49:26.227978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentences = []\n",
    "\n",
    "for item in qa:\n",
    "    sentences.append(preprocess(item[\"reference\"]))\n",
    "    sentences.append(preprocess(item[\"student_answer\"]))\n",
    "\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1\n",
    ")\n",
    "\n",
    "def sentence_vector(tokens, model):\n",
    "    vectors = [model.wv[w] for w in tokens if w in model.wv]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "def semantic_similarity(ref_text, stu_text, model):\n",
    "    ref_tokens = preprocess(ref_text)\n",
    "    stu_tokens = preprocess(stu_text)\n",
    "\n",
    "    v_ref = sentence_vector(ref_tokens, model).reshape(1, -1)\n",
    "    v_stu = sentence_vector(stu_tokens, model).reshape(1, -1)\n",
    "\n",
    "    return cosine_similarity(v_ref, v_stu)[0][0]\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for item in qa:\n",
    "    sim = semantic_similarity(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"],\n",
    "        w2v\n",
    "    )\n",
    "\n",
    "    len_ratio = len(preprocess(item[\"student_answer\"])) / max(\n",
    "        1, len(preprocess(item[\"reference\"]))\n",
    "    )\n",
    "\n",
    "    X.append([sim, len_ratio])\n",
    "    y.append(item[\"score\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.clip(pred, 0, 5)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, pred))\n",
    "\n",
    "for p, a in zip(pred[:5], y_test[:5]):\n",
    "    print(f\"Predicted: {p:.2f} | Actual: {a}\")\n"
   ],
   "id": "f95036caab9c6c5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.30117919508534274\n",
      "Predicted: 4.19 | Actual: 4\n",
      "Predicted: 4.04 | Actual: 4\n",
      "Predicted: 3.71 | Actual: 4\n",
      "Predicted: 1.31 | Actual: 2\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Capturing Semantics using GloVE",
   "id": "94b27e7558856720"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:49:39.667580Z",
     "start_time": "2026-01-17T15:49:26.314509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_glove(path):\n",
    "    embeddings = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "glove = load_glove(\"glove/glove.6B.100d.txt\")\n",
    "EMB_DIM = 100\n",
    "\n",
    "def sentence_vector_glove(tokens, embeddings, dim=100):\n",
    "    vectors = [embeddings[w] for w in tokens if w in embeddings]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def semantic_similarity_glove(ref_text, stu_text, embeddings):\n",
    "    ref_tokens = preprocess(ref_text)\n",
    "    stu_tokens = preprocess(stu_text)\n",
    "\n",
    "    v_ref = sentence_vector_glove(ref_tokens, embeddings).reshape(1, -1)\n",
    "    v_stu = sentence_vector_glove(stu_tokens, embeddings).reshape(1, -1)\n",
    "\n",
    "    return cosine_similarity(v_ref, v_stu)[0][0]\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for item in qa:\n",
    "    sim = semantic_similarity_glove(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"],\n",
    "        glove\n",
    "    )\n",
    "\n",
    "    features = [\n",
    "        sim,\n",
    "        len(preprocess(item[\"student_answer\"]))\n",
    "    ]\n",
    "\n",
    "    X.append(features)\n",
    "    y.append(item[\"score\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"R² score:\", model.score(X_test, y_test))\n",
    "\n",
    "for p, a in zip(pred[:5], y_test[:5]):\n",
    "    print(f\"Predicted: {p:.2f} | Actual: {a}\")\n"
   ],
   "id": "7cbbb5d9a1ef1371",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score: 0.27775230967931475\n",
      "Predicted: 4.68 | Actual: 4\n",
      "Predicted: 2.89 | Actual: 4\n",
      "Predicted: 4.40 | Actual: 4\n",
      "Predicted: 1.43 | Actual: 2\n"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation Based purely on cosine similarity",
   "id": "6ff1576adb4311c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:56:33.292209Z",
     "start_time": "2026-01-17T15:56:33.269829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mark_from_similarity(similarity, max_marks=5):\n",
    "    sim = max(0.0, min(1.0, similarity))  # clamp\n",
    "    return round(sim * max_marks, 2)\n",
    "\n",
    "for item in qa:\n",
    "    sim = semantic_similarity_glove(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"],\n",
    "        glove\n",
    "    )\n",
    "\n",
    "    marks = mark_from_similarity(sim, max_marks=5)\n",
    "\n",
    "    print(\"Q:\", item[\"question\"])\n",
    "    print(\"A:\", item[\"reference\"])\n",
    "    print(\"A:\", item[\"student_answer\"])\n",
    "    print(\"Similarity:\", round(sim, 3))\n",
    "    print(\"Marks:\", marks)\n",
    "    print(\"-\")\n",
    "\n"
   ],
   "id": "45f8c6358ad2f844",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What were the main causes of the French Revolution?\n",
      "A: The French Revolution was caused by social inequality, financial crisis, heavy taxation, and the absolute monarchy of France.\n",
      "A: The revolution happened because of inequality and financial problems in France.\n",
      "Similarity: 0.913\n",
      "Marks: 4.57\n",
      "-\n",
      "Q: What were the main causes of the French Revolution?\n",
      "A: The French Revolution was caused by social inequality, financial crisis, heavy taxation, and the absolute monarchy of France.\n",
      "A: It happened because people were unhappy.\n",
      "Similarity: 0.662\n",
      "Marks: 3.31\n",
      "-\n",
      "Q: What were the main causes of the French Revolution?\n",
      "A: The French Revolution was caused by social inequality, financial crisis, heavy taxation, and the absolute monarchy of France.\n",
      "A: It started because of wars with other countries.\n",
      "Similarity: 0.769\n",
      "Marks: 3.84\n",
      "-\n",
      "Q: What is meant by social inequality in France before 1789?\n",
      "A: Social inequality referred to unequal privileges enjoyed by the clergy and nobility, while the Third Estate bore heavy taxes.\n",
      "A: The clergy and nobility had privileges while common people paid taxes.\n",
      "Similarity: 0.915\n",
      "Marks: 4.57\n",
      "-\n",
      "Q: What is meant by social inequality in France before 1789?\n",
      "A: Social inequality referred to unequal privileges enjoyed by the clergy and nobility, while the Third Estate bore heavy taxes.\n",
      "A: Some people were richer than others.\n",
      "Similarity: 0.731\n",
      "Marks: 3.65\n",
      "-\n",
      "Q: What was the role of taxation in causing the French Revolution?\n",
      "A: Heavy taxation on the Third Estate while the clergy and nobility were exempt contributed to widespread dissatisfaction.\n",
      "A: Taxes were heavy on common people and made them angry.\n",
      "Similarity: 0.826\n",
      "Marks: 4.13\n",
      "-\n",
      "Q: What was the role of taxation in causing the French Revolution?\n",
      "A: Heavy taxation on the Third Estate while the clergy and nobility were exempt contributed to widespread dissatisfaction.\n",
      "A: Taxes were fair for everyone.\n",
      "Similarity: 0.717\n",
      "Marks: 3.59\n",
      "-\n",
      "Q: Who were the members of the Third Estate?\n",
      "A: The Third Estate consisted of peasants, workers, and the middle class, forming the majority of the French population.\n",
      "A: The Third Estate included peasants, workers and the middle class.\n",
      "Similarity: 0.949\n",
      "Marks: 4.74\n",
      "-\n",
      "Q: Who were the members of the Third Estate?\n",
      "A: The Third Estate consisted of peasants, workers, and the middle class, forming the majority of the French population.\n",
      "A: The Third Estate was made of nobles.\n",
      "Similarity: 0.809\n",
      "Marks: 4.05\n",
      "-\n",
      "Q: What was the significance of the fall of the Bastille?\n",
      "A: The fall of the Bastille symbolized the end of royal tyranny and marked the beginning of the French Revolution.\n",
      "A: It showed the end of the king’s power and the start of the revolution.\n",
      "Similarity: 0.848\n",
      "Marks: 4.24\n",
      "-\n",
      "Q: What was the significance of the fall of the Bastille?\n",
      "A: The fall of the Bastille symbolized the end of royal tyranny and marked the beginning of the French Revolution.\n",
      "A: A prison was destroyed in Paris.\n",
      "Similarity: 0.674\n",
      "Marks: 3.37\n",
      "-\n",
      "Q: What did the Declaration of the Rights of Man state?\n",
      "A: The Declaration stated that all men are born free and equal in rights and emphasized liberty, equality, and fraternity.\n",
      "A: It said people are born free and equal and have rights.\n",
      "Similarity: 0.906\n",
      "Marks: 4.53\n",
      "-\n",
      "Q: What did the Declaration of the Rights of Man state?\n",
      "A: The Declaration stated that all men are born free and equal in rights and emphasized liberty, equality, and fraternity.\n",
      "A: It supported the king.\n",
      "Similarity: 0.64\n",
      "Marks: 3.2\n",
      "-\n",
      "Q: What was meant by absolute monarchy?\n",
      "A: Absolute monarchy was a system where the king held unlimited power and was not bound by laws or a constitution.\n",
      "A: It meant the king had unlimited power.\n",
      "Similarity: 0.882\n",
      "Marks: 4.41\n",
      "-\n",
      "Q: What was meant by absolute monarchy?\n",
      "A: Absolute monarchy was a system where the king held unlimited power and was not bound by laws or a constitution.\n",
      "A: It was a democratic system.\n",
      "Similarity: 0.756\n",
      "Marks: 3.78\n",
      "-\n",
      "Q: Why did the Third Estate oppose the Old Regime?\n",
      "A: The Third Estate opposed the Old Regime due to heavy taxation, lack of political rights, and social inequality.\n",
      "A: They were taxed heavily and had no political power.\n",
      "Similarity: 0.89\n",
      "Marks: 4.45\n",
      "-\n",
      "Q: Why did the Third Estate oppose the Old Regime?\n",
      "A: The Third Estate opposed the Old Regime due to heavy taxation, lack of political rights, and social inequality.\n",
      "A: They liked the system.\n",
      "Similarity: 0.654\n",
      "Marks: 3.27\n",
      "-\n",
      "Q: What role did the middle class play in the revolution?\n",
      "A: The middle class provided leadership and ideas for reform and equality during the French Revolution.\n",
      "A: The middle class led reforms and demanded equality.\n",
      "Similarity: 0.933\n",
      "Marks: 4.66\n",
      "-\n",
      "Q: What role did the middle class play in the revolution?\n",
      "A: The middle class provided leadership and ideas for reform and equality during the French Revolution.\n",
      "A: They did not participate.\n",
      "Similarity: 0.743\n",
      "Marks: 3.72\n",
      "-\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-17T15:58:51.971043Z",
     "start_time": "2026-01-17T15:58:46.471886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "for item in qa:\n",
    "    tokens = preprocess(item[\"reference\"])\n",
    "    ref_uni |= set(tokens)\n",
    "    ref_bi |= set(ngrams(tokens, 2))\n",
    "    ref_tri |= set(ngrams(tokens, 3))\n",
    "\n",
    "def semantic_similarity(ref, stu):\n",
    "    emb = sbert.encode([ref, stu])\n",
    "    return cosine_similarity([emb[0]], [emb[1]])[0][0]\n",
    "\n",
    "def keyword_overlap(stu):\n",
    "    tokens = preprocess(stu)\n",
    "    u = set(tokens)\n",
    "    b = set(ngrams(tokens, 2))\n",
    "    t = set(ngrams(tokens, 3))\n",
    "\n",
    "    uni = len(u & ref_uni) / max(len(ref_uni), 1)\n",
    "    bi  = len(b & ref_bi)  / max(len(ref_bi), 1)\n",
    "    tri = len(t & ref_tri) / max(len(ref_tri), 1)\n",
    "\n",
    "    return 0.2 * uni + 0.3 * bi + 0.5 * tri\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for item in qa:\n",
    "    sim = semantic_similarity(\n",
    "        item[\"reference\"],\n",
    "        item[\"student_answer\"]\n",
    "    )\n",
    "\n",
    "    key = keyword_overlap(item[\"student_answer\"])\n",
    "    length = len(preprocess(item[\"student_answer\"]))\n",
    "\n",
    "    X.append([sim, key, length])\n",
    "    y.append(item[\"score\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"R² score:\", round(model.score(X_test, y_test), 3))\n",
    "\n",
    "for p, a in zip(pred[:5], y_test[:5]):\n",
    "    print(f\"Predicted: {p:.2f} | Actual: {a}\")\n"
   ],
   "id": "ead27594d366cf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score: 0.559\n",
      "Predicted: 4.95 | Actual: 4\n",
      "Predicted: 4.02 | Actual: 4\n",
      "Predicted: 4.48 | Actual: 4\n",
      "Predicted: 1.57 | Actual: 2\n"
     ]
    }
   ],
   "execution_count": 189
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
